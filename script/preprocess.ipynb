{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、数据预处理\n",
    "\n",
    "### 1.1、转换数据格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:53<00:00, 278.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import shutil\n",
    "\n",
    "root = \"./trainning set\"\n",
    "save_root = \"./icpr2024\"\n",
    "os.makedirs(os.path.join(save_root, \"img\"), exist_ok=True)\n",
    "\n",
    "with open(os.path.join(save_root, \"img_src.txt\"), 'w', encoding='utf-8') as fw:\n",
    "    for file in tqdm.tqdm(os.listdir(os.path.join(root, 'png'))):\n",
    "        name = os.path.splitext(file)[0]\n",
    "        json_file = f\"{name}.json\"\n",
    "        \n",
    "        with open(os.path.join(root, \"json\", json_file), 'r', encoding=\"utf-8\") as fp:\n",
    "            data = json.load(fp)\n",
    "\n",
    "        shutil.copy(os.path.join(root, 'png', file),\n",
    "                    os.path.join(save_root, 'img', file))\n",
    "        \n",
    "        \n",
    "        fw.write(f\"{file}\\t{data['latex_styled']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2、数据清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:14<00:00, 1011.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "\n",
    "img_dir = \"./icpr2024/img\"\n",
    "label_file = \"./icpr2024/img_src.txt\"\n",
    "save_label_file = \"./icpr2024/img.txt\"\n",
    "\n",
    "err_dict = {\n",
    "    \"\\\\begin {array}\":\"\\\\begin{array}\",\n",
    "    \"\\\\end {array}\":\"\\\\end{array}\",\n",
    "    \"\\\\begin { a l i g n e d }\":\"\\\\begin{aligned}\",\n",
    "    \"\\\\end { a l i g n e d }\":\"\\\\end{aligned}\",\n",
    "    \"\\\\begin { a r r a y }\":\"\\\\begin{array}\",\n",
    "    \"\\\\end { a r r a y }\":\"\\\\end{array}\",\n",
    "    \"\\\\begin { c a s e s }\":\"\\\\begin{cases}\",\n",
    "    \"\\\\end { c a s e s }\":\"\\\\end{cases}\",\n",
    "    \"\\\\begin { m a t r i x }\":\"\\\\begin{matrix}\",\n",
    "    \"\\\\end { m a t r i x }\":\"\\\\end{matrix}\",\n",
    "    \"\\\\begin { b m a t r i x }\":\"\\\\begin{bmatrix}\",\n",
    "    \"\\\\end { b m a t r i x }\":\"\\\\end{bmatrix}\",\n",
    "    \"\\\\le s s d o t\":\"\\\\lessdot\",\n",
    "    \"\\\\le s s g t r\":\"\\\\lessgtr\",\n",
    "    \"\\\\le a d s t o\":\"\\\\leadsto\",\n",
    "    \"\\\\le s s s i m\":\"\\\\lesssim\",\n",
    "    \"\\\\le q s l a n t\":\"\\\\leqslant\",\n",
    "    \"\\\\le f t r i g h t h a r p o o n s\":\"\\\\leftrightharpoons\",\n",
    "    \"\\\\le f t r i g h t a r r o w s\":\"\\\\leftrightarrows\",\n",
    "    \"\\\\le f t l e f t a r r o w s\":\"\\\\leftleftarrows\",\n",
    "    \"\\\\le f t r i g h t a r r o w\":\"\\\\leftrightarrow\",\n",
    "    \"\\\\le f t a r r o w\":\"\\\\leftarrow\",\n",
    "    \"\\\\le f t .\":\"\\\\left.\",\n",
    "    \"\\\\le f t\":\"\\\\left\",\n",
    "    \"\\\\le q\":\"\\\\leq\",\n",
    "    \"\\\\ge q\":\"\\\\geq\",\n",
    "    \"\\\\geq s l a n t\":\"\\\\geqslant\",\n",
    "    \"\\\\ne q\":\"\\\\neq\",\n",
    "    \"\\\\cdot s\":\"\\\\cdots\",\n",
    "    \"\\\\ne w l i n e\":\"\\\\newline\",\n",
    "    \"\\\\lim i t s\":\"\\\\limits\",\n",
    "    \"\\\\in f t y\":\"\\\\infty\",\n",
    "    \"\\\\in t\":\"\\\\int\",\n",
    "    \"\\\\in f\":\"\\\\inf\",\n",
    "    \"\\\\not i n\":\"\\\\notin\",\n",
    "    \"\\\\sim e q\":\"\\\\simeq\",\n",
    "    \"\\\\dot e q\":\"\\\\doteq\",\n",
    "    \"\\\\ l d o t s\":\"\\\\ldots\",\n",
    "    \"\\\\ c d o t s\":\"\\\\cdots\",\n",
    "    \"\\\\doteq d o t\":\"\\\\doteqdot\",\n",
    "    \"\\\\circ l e a r r o w r i g h t\":\"\\\\circlearrowright\",\n",
    "    \"\\\\circ l e a r r o w l e f t\":\"\\\\circlearrowleft\",\n",
    "    \"\\\\circ l e d a s t\":\"\\\\circledast\",\n",
    "    \"\\\\ddot s\":\"\\\\ddots\",\n",
    "    \"\\\\ m a t h r m\":\"\\\\mathrm\",\n",
    "    \" \\\\ |\":\" \\\\|\",\n",
    "    \"\\\\ r a n g l e\":\"\\\\rangle\",\n",
    "    \"\\\\ l a n g l e\":\"\\\\langle\",\n",
    "    \"\\\\right a r r o w\":\"\\\\rightarrow\",\n",
    "    \"\\\\left a r r o w\":\"\\\\leftarrow\",\n",
    "    \"\\\\to p\":\"\\\\top\",\n",
    "    \"\\\\lt i m e s\": \"\\\\ltimes\",\n",
    "    \"\\\\gt r s i m\":\"\\\\gtrsim\",\n",
    "    \"\\\\gt r l e s s\":\"\\\\gtrless\",\n",
    "    \"\\\\ll l\":\"\\\\lll\",\n",
    "    \"\\\\gg g\":\"\\\\ggg\",\n",
    "    \"\\\\ne g\":\"\\\\neg\",\n",
    "    \"\\\\ne a r r o w\":\"\\\\nearrow\",\n",
    "    \"\\\\mu l t i r o w\":\"\\\\multirow\",\n",
    "    \"\\\\mu l t i c o l u m n\":\"\\\\multicolumn\",\n",
    "    \"\\\\mu l t i m a p\":\"\\\\multimap\",\n",
    "    \"\\\\pi t c h f o r k\":\"\\\\pitchfork\",\n",
    "    \"\\\\ll c o r n e r\":\"\\\\llcorner\",\n",
    "    \"\\\\ll b r a c k e t\":\"\\\\llbracket\",\n",
    "    \"\\\\succ c u r l y e q\":\"\\\\succcurlyeq\",\n",
    "    \"\\\\succ s i m\":\"\\\\succsim\",\n",
    "    \"\\\\succ e q\":\"\\\\succeq\",\n",
    "    \"\\\\prec c u r l y e q\":\"\\\\preccurlyeq\",\n",
    "    \"\\\\prec s i m\":\"\\\\precsim\",\n",
    "    \"\\\\prec e q\":\"\\\\preceq\",\n",
    "    \"\\\\nprec e q\":\"\\\\npreceq\",\n",
    "    \"\\\\check m a r k\":\"\\\\checkmark\",\n",
    "    \"\\\\right l e f t h a r p o o n s\":\"\\\\rightleftharpoons\",\n",
    "    \"\\\\right r i g h t a r r o w s\":\"\\\\rightrightarrows\",\n",
    "    \"\\\\right s q u i g a r r o w\":\"\\\\rightsquigarrow\",\n",
    "    \"\\\\right l e f t a r r o w s\":\"\\\\rightleftarrows\",\n",
    "    \"\\\\right a r r o w\":\"\\\\rightarrow\",\n",
    "    \"\\\\nsucc e q\":\"\\\\nsucceq\",\n",
    "    \"\\\\subset n e q q\":\"\\\\subsetneqq\",\n",
    "    \"\\\\subset n e q\":\"\\\\subsetneq\",\n",
    "    \"\\\\subset n e q q\":\"\\\\subsetneqq\",\n",
    "    \"\\\\subset e q\":\"\\\\subseteq\",\n",
    "    \"\\\\supset n e q q\":\"\\\\supsetneqq\",\n",
    "    \"\\\\supset n e q\":\"\\\\supsetneq\",\n",
    "    \"\\\\supset e q q\":\"\\\\supseteqq\",\n",
    "    \"\\\\supset e q\":\"\\\\supseteq\",\n",
    "    \"\\\\triangle r i g h t\":\"\\\\triangleright\",\n",
    "    \"\\\\triangle l e f t\":\"\\\\triangleleft\",\n",
    "    \"\\\\triangle q\":\"\\\\triangleq\",\n",
    "    \"\\\\ s u b s t a c k\":\"\\\\substack\",\n",
    "    \"\\\\ s u p\":\"\\\\sup\",\n",
    "    \"\\\\sqsubset e q\":\"\\\\sqsubseteq\",\n",
    "    \"\\\\sqsupset e q\":\"\\\\sqsupseteq\",\n",
    "    \"\\\\supsetneq q\":\"\\\\supsetneqq\",\n",
    "    \"\\\\subsetneq q\":\"\\\\subsetneqq\",\n",
    "    \"\\\\leftrightarrow s\":\"\\\\leftrightarrows\",\n",
    "    \"\\\\ L o n g r i g h t a r r o w\":\"\\\\Longrightarrow\",\n",
    "    \"\\\\ L o n g l e f t r i g h t a r r o w\":\"\\\\Longleftrightarrow\",\n",
    "    \"\\\\ l o n g l e f t r i g h t a r r o w\":\"\\\\longleftrightarrow\",\n",
    "    \"\\\\ s t a c k r e l\":\"\\\\stackrel\",\n",
    "    \"\\\\ t e x t\":\"\\\\text\",\n",
    "    \"\\\\ m a x\":\"\\\\max\",\n",
    "    \"\\\\ m i n\":\"\\\\min\",\n",
    "    \"\\\\ m i d\":\"\\\\mid\",\n",
    "    \"\\\\ b o x p l u s\":\"\\\\boxplus\",\n",
    "    \"\\\\ s h a r p\":\"\\\\sharp\",\n",
    "    \"\\\\ v a r O m e g a\":\"\\\\varOmega\",\n",
    "    \"\\\\ v a r k a p p a\":\"\\\\varkappa\",\n",
    "    \"\\\\ o v e r p a r e n\":\"\\\\overparen\",\n",
    "    \"\\\\ d d a g g e r\":\"\\\\ddagger\",\n",
    "    \"\\\\ h d a s h l i n e\":\"\\\\hdashline\",\n",
    "    \" \\\\ l g\":\" \\\\lg\",\n",
    "    \"\\\\ B o x\":\"\\\\Box\",\n",
    "    \"\\\\ a r c s i n\":\"\\\\arcsin\",\n",
    "    \"\\\\ a r c c o s\":\"\\\\arccos\",\n",
    "    \"\\\\ a r c t a n\":\"\\\\arctan\",\n",
    "    \"\\\\ r m\":\"\\\\rm\",\n",
    "    \"\\\\ c o t\":\"\\\\cot\",\n",
    "    \"\\\\ s e c\":\"\\\\sec\",\n",
    "    \"\\\\ c s c\":\"\\\\csc\",\n",
    "    \"\\\\ e x p\":\"\\\\exp\",\n",
    "    \"\\\\ i i i n t\":\"\\\\iiint\",\n",
    "    \"\\\\ i i n t\":\"\\\\iint\",\n",
    "    \"\\\\ s q u a r e\":\"\\\\square\",\n",
    "    \"\\\\ b m o d\":\"\\\\bmod\",\n",
    "    \"\\\\ a r g\":\"\\\\arg\",\n",
    "    \"\\\\ #\":\"\\\\#\",\n",
    "    \" \\\\ &\":\" \\\\&\",\n",
    "    \"\\\\ \\\\{\": \"\\\\\\\\ {\",\n",
    "    \"< s p a c e >\":\"<space/>\",\n",
    "    \"< / s p a c e >\":\"<space/>\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "with open('tokenizer.txt', 'r', encoding='utf-8') as fp:\n",
    "    latex = [line.strip() for line in fp.readlines()]\n",
    "    \n",
    "def add_space(text, latex):\n",
    "    for latex in latex:\n",
    "        if text.find(latex) != -1:\n",
    "            text = text.replace(latex, f\" {latex} \")\n",
    "            \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "with open(save_label_file, 'w', encoding='utf-8') as fw:\n",
    "    with open(label_file, 'r', encoding='utf-8') as fp:\n",
    "        for line in tqdm.tqdm(fp.readlines()):\n",
    "            name, label = line.strip().split('\\t')\n",
    "            label = label.strip('\\n')\n",
    "            if not os.path.exists(os.path.join(img_dir, name)):\n",
    "                continue\n",
    "\n",
    "            label = add_space(label, latex=latex)\n",
    "            \n",
    "            lab_list = []\n",
    "            for s in label.split(' '):\n",
    "                if s == '': continue\n",
    "                elif s in latex: lab_list.append(s)\n",
    "                else:\n",
    "                    lab_list += list(s)  \n",
    "            \n",
    "            clear_latex = ' '.join(lab_list)\n",
    "         \n",
    "            for key in err_dict.keys():\n",
    "                if clear_latex.find(key) != -1:\n",
    "                    clear_latex = clear_latex.replace(key, err_dict[key])\n",
    "            \n",
    "            \n",
    "            # print(clear_latex) \n",
    "            fw.write(f\"{name}\\t{clear_latex}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3、生成字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = [\"./icpr2024/img.txt\"]\n",
    "\n",
    "total_lines = []\n",
    "for labels_file in labels_list:\n",
    "    with open(labels_file, 'r', encoding='utf-8') as fp:\n",
    "        total_lines += fp.readlines()\n",
    "    \n",
    "with open(\"./dict.txt\", 'w', encoding='utf-8') as fw:\n",
    "    lab_list = []\n",
    "    for line in total_lines:\n",
    "        name, labels = line.strip().split('\\t')\n",
    "        lab_list += labels.split(' ')\n",
    "    lab_list = list(set(lab_list))\n",
    "    lab_list = sorted(lab_list)\n",
    "    for l in lab_list:\n",
    "        fw.write(f'{l}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4、切分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:01<00:00, 7975.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "\n",
    "labels = [\n",
    "    \"./icpr2024/img.txt\",\n",
    "]\n",
    "\n",
    "dirs = [\n",
    "    \"./icpr2024/img\",\n",
    "]\n",
    "\n",
    "dirs_label=[\n",
    "    \"img\",\n",
    "]\n",
    "\n",
    "total_labels = {}\n",
    "for idx,(label_file,im_dir) in enumerate(zip(labels,dirs)):\n",
    "    \n",
    "    with open(label_file,'r',encoding=\"utf-8\") as fp:\n",
    "        lines = fp.readlines()\n",
    "        \n",
    "    for line in tqdm.tqdm(lines):\n",
    "        name,lab = line.strip().split('\\t')\n",
    "        \n",
    "        lab = lab.strip().split(' ')\n",
    "        if not os.path.exists(os.path.join(im_dir,name)):\n",
    "            continue\n",
    "        \n",
    "        # img = cv2.imread(os.path.join(im_dir,name))\n",
    "        # if img is None :\n",
    "        #     continue\n",
    "        \n",
    "        # h,w,c = img.shape\n",
    "        # if h <32 or w <32:\n",
    "        #     continue\n",
    "            \n",
    "        total_labels[f\"{dirs_label[idx]}/{name}\"] = lab\n",
    "\n",
    "split = 0.95\n",
    "\n",
    "lkeys = list(total_labels.keys())\n",
    "random.shuffle(lkeys)\n",
    "print(len(lkeys))\n",
    "\n",
    "split_idx = int(len(lkeys)*0.95)\n",
    "\n",
    "train=lkeys[:split_idx]\n",
    "val = lkeys[split_idx:]\n",
    "\n",
    "\n",
    "with open(\"train.txt\",\"w\",encoding=\"utf-8\") as fw:\n",
    "    for key in train:\n",
    "        fw.write(f\"{key}\\t{' '.join(total_labels[key])}\\n\")\n",
    "\n",
    "with open(\"val.txt\",\"w\",encoding=\"utf-8\") as fw:\n",
    "    for key in val:\n",
    "        fw.write(f\"{key}\\t{' '.join(total_labels[key])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、数据统计\n",
    "\n",
    "### 2.1、标签图片尺寸统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================>H的参数：\n",
      "均值: 416.7778\n",
      "中位数: 374.0\n",
      "最大值: 2483\n",
      "最小值: 115\n",
      "===================>W的参数：\n",
      "均值: 1615.7956666666666\n",
      "中位数: 1525.5\n",
      "最大值: 4446\n",
      "最小值: 181\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "h_hist = []\n",
    "w_hist = []\n",
    "root = \"./icpr_data/img\"\n",
    "for file in os.listdir(root):\n",
    "    img = cv2.imread(os.path.join(root, file))\n",
    "    h, w = img.shape[:2]\n",
    "    h_hist.append(h)\n",
    "    w_hist.append(w)\n",
    "\n",
    "#H\n",
    "print(\"===================>H的参数：\")\n",
    "print(\"均值:\", np.mean(h_hist))\n",
    "print(\"中位数:\", np.median(h_hist))\n",
    "print(\"最大值:\", np.max(h_hist))\n",
    "print(\"最小值:\", np.min(h_hist))\n",
    "#W\n",
    "print(\"===================>W的参数：\")\n",
    "print(\"均值:\", np.mean(w_hist))\n",
    "print(\"中位数:\", np.median(w_hist))\n",
    "print(\"最大值:\", np.max(w_hist))\n",
    "print(\"最小值:\", np.min(w_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_list = []\n",
    "with open(\"./icpr2024/img.txt\", 'r', encoding=\"utf-8\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        label = line.strip().split('\\t')[-1]\n",
    "        lab_list.append(len(label.split(\" \")))\n",
    "\n",
    "print(\"===================>标签长度参数：\")\n",
    "print(\"均值:\", np.mean(lab_list))\n",
    "print(\"中位数:\", np.median(lab_list))\n",
    "print(\"最大值:\", np.max(lab_list))\n",
    "print(\"最小值:\", np.min(lab_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
